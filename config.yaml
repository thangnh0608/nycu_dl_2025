dataset:
  train_dir: ./data/train
  test_dir: ./data/test
  val_dir: ./data/val
  image_size: 200
  num_workers: 4

training:
  val: False
  batch_size: 128
  lr: 1e-4
  epochs: 25
  w_decay: 0.05
  warmup: 0.05
  ema_decay: 0.998
  amp: True
  grad_clipping: 2.0

  seed: 42
  layerwise_lr_decay: 0.9
  lr_scheduler: linear

  lr_scheduler_params:
    linear:
      warmup_steps: 0.05
      min_lr: 1e-8

    cosine_warmup:
      warmup_steps: 0.05
      cycles: 2
      min_lr: 1e-8

augmentation:
  # Pad:
  #   padding: 4
  # RandomResizedCrop:
  #   size: 224
  #   scale: [0.9, 1.1]
  # JPEG:
  #   quality: 90
  # RandomHorizontalFlip:
  #   p: 0.5


model:
  name: facebook/convnextv2-tiny-22k-224
  num_classes: 2
  model_params:
    facebook/convnextv2-tiny-22k-224:
      drop_path_rate: 0.4
  weight:

experiment:
  project: deeplearing_2025
  run_name: convnextv2-tiny_lr_decay_200_timm_search
  save_dir: outputs/convnextv2_tiny
